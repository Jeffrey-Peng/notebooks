{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install arize-phoenix openai \"arize-phoenix[evals]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreypeng/Projects/LLM_Project/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/jeffreypeng/Projects/LLM_Project/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:phoenix.config:üìã Ensuring phoenix working directory: /Users/jeffreypeng/.phoenix\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "session = px.launch_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [opentelemetry.instrumentation.instrumentor] Attempting to instrument while already instrumented\n"
     ]
    }
   ],
   "source": [
    "from phoenix.trace.openai import OpenAIInstrumentor\n",
    "\n",
    "# Initialize OpenAI auto-instrumentation\n",
    "OpenAIInstrumentor().instrument()\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize an OpenAI client\n",
    "client = OpenAI(api_key='')\n",
    "\n",
    "# Define a conversation with a user message\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello, can you help me with something?\"}\n",
    "]\n",
    "\n",
    "# Generate a response from the assistant\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=conversation,\n",
    ")\n",
    "\n",
    "# Extract and print the assistant's reply\n",
    "# The traces will be available in the Phoenix App for the above messsages\n",
    "assistant_reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreypeng/Projects/LLM_Project/lib/python3.9/site-packages/phoenix/trace/dsl/query.py:746: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  df_attributes = pd.DataFrame.from_records(\n"
     ]
    }
   ],
   "source": [
    "# You can export a dataframe from the session\n",
    "df = px.Client().get_spans_dataframe()\n",
    "\n",
    "# Note that you can apply a filter if you would like to export only a sub-set of spans\n",
    "# df = px.Client().get_spans_dataframe('span_kind == \"RETRIEVER\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>span_kind</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>status_code</th>\n",
       "      <th>status_message</th>\n",
       "      <th>events</th>\n",
       "      <th>context.span_id</th>\n",
       "      <th>context.trace_id</th>\n",
       "      <th>...</th>\n",
       "      <th>attributes.openinference.span.kind</th>\n",
       "      <th>attributes.input.value</th>\n",
       "      <th>attributes.input.mime_type</th>\n",
       "      <th>attributes.llm.token_count.total</th>\n",
       "      <th>attributes.llm.model_name</th>\n",
       "      <th>attributes.llm.output_messages</th>\n",
       "      <th>attributes.output.mime_type</th>\n",
       "      <th>attributes.llm.token_count.completion</th>\n",
       "      <th>attributes.output.value</th>\n",
       "      <th>attributes.llm.token_count.prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>context.span_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1459dd58d4cc48ec</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-08-19 15:22:23.856855+00:00</td>\n",
       "      <td>2024-08-19 15:22:26.530612+00:00</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>APIConnectionError: Connection error.</td>\n",
       "      <td>[{'attributes': {'exception.escaped': 'False',...</td>\n",
       "      <td>1459dd58d4cc48ec</td>\n",
       "      <td>7bb35426b45941cd1567790bea2ba849</td>\n",
       "      <td>...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911ec6f836a86f3</th>\n",
       "      <td>ChatCompletion</td>\n",
       "      <td>LLM</td>\n",
       "      <td>None</td>\n",
       "      <td>2024-08-19 15:23:54.428521+00:00</td>\n",
       "      <td>2024-08-19 15:23:55.075062+00:00</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>9911ec6f836a86f3</td>\n",
       "      <td>bcc9ec85ca04aa9c3233667749e8d179</td>\n",
       "      <td>...</td>\n",
       "      <td>LLM</td>\n",
       "      <td>{\"messages\": [{\"role\": \"system\", \"content\": \"Y...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>45.0</td>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>[{'message.content': 'Of course! I'll do my be...</td>\n",
       "      <td>application/json</td>\n",
       "      <td>19.0</td>\n",
       "      <td>{\"id\":\"chatcmpl-9xyWYkCTNIOgRKYRlblRgo6ZSIJ4V\"...</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name span_kind parent_id  \\\n",
       "context.span_id                                        \n",
       "1459dd58d4cc48ec  ChatCompletion       LLM      None   \n",
       "9911ec6f836a86f3  ChatCompletion       LLM      None   \n",
       "\n",
       "                                       start_time  \\\n",
       "context.span_id                                     \n",
       "1459dd58d4cc48ec 2024-08-19 15:22:23.856855+00:00   \n",
       "9911ec6f836a86f3 2024-08-19 15:23:54.428521+00:00   \n",
       "\n",
       "                                         end_time status_code  \\\n",
       "context.span_id                                                 \n",
       "1459dd58d4cc48ec 2024-08-19 15:22:26.530612+00:00       ERROR   \n",
       "9911ec6f836a86f3 2024-08-19 15:23:55.075062+00:00          OK   \n",
       "\n",
       "                                         status_message  \\\n",
       "context.span_id                                           \n",
       "1459dd58d4cc48ec  APIConnectionError: Connection error.   \n",
       "9911ec6f836a86f3                                          \n",
       "\n",
       "                                                             events  \\\n",
       "context.span_id                                                       \n",
       "1459dd58d4cc48ec  [{'attributes': {'exception.escaped': 'False',...   \n",
       "9911ec6f836a86f3                                                 []   \n",
       "\n",
       "                   context.span_id                  context.trace_id  ...  \\\n",
       "context.span_id                                                       ...   \n",
       "1459dd58d4cc48ec  1459dd58d4cc48ec  7bb35426b45941cd1567790bea2ba849  ...   \n",
       "9911ec6f836a86f3  9911ec6f836a86f3  bcc9ec85ca04aa9c3233667749e8d179  ...   \n",
       "\n",
       "                 attributes.openinference.span.kind  \\\n",
       "context.span_id                                       \n",
       "1459dd58d4cc48ec                                LLM   \n",
       "9911ec6f836a86f3                                LLM   \n",
       "\n",
       "                                             attributes.input.value  \\\n",
       "context.span_id                                                       \n",
       "1459dd58d4cc48ec  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "9911ec6f836a86f3  {\"messages\": [{\"role\": \"system\", \"content\": \"Y...   \n",
       "\n",
       "                 attributes.input.mime_type attributes.llm.token_count.total  \\\n",
       "context.span_id                                                                \n",
       "1459dd58d4cc48ec           application/json                              NaN   \n",
       "9911ec6f836a86f3           application/json                             45.0   \n",
       "\n",
       "                 attributes.llm.model_name  \\\n",
       "context.span_id                              \n",
       "1459dd58d4cc48ec                      None   \n",
       "9911ec6f836a86f3        gpt-3.5-turbo-0125   \n",
       "\n",
       "                                     attributes.llm.output_messages  \\\n",
       "context.span_id                                                       \n",
       "1459dd58d4cc48ec                                               None   \n",
       "9911ec6f836a86f3  [{'message.content': 'Of course! I'll do my be...   \n",
       "\n",
       "                 attributes.output.mime_type  \\\n",
       "context.span_id                                \n",
       "1459dd58d4cc48ec                        None   \n",
       "9911ec6f836a86f3            application/json   \n",
       "\n",
       "                 attributes.llm.token_count.completion  \\\n",
       "context.span_id                                          \n",
       "1459dd58d4cc48ec                                   NaN   \n",
       "9911ec6f836a86f3                                  19.0   \n",
       "\n",
       "                                            attributes.output.value  \\\n",
       "context.span_id                                                       \n",
       "1459dd58d4cc48ec                                               None   \n",
       "9911ec6f836a86f3  {\"id\":\"chatcmpl-9xyWYkCTNIOgRKYRlblRgo6ZSIJ4V\"...   \n",
       "\n",
       "                  attributes.llm.token_count.prompt  \n",
       "context.span_id                                      \n",
       "1459dd58d4cc48ec                                NaN  \n",
       "9911ec6f836a86f3                               26.0  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from phoenix.trace.trace_dataset import TraceDataset\n",
    "from phoenix.trace.utils import json_lines_to_df\n",
    "\n",
    "# Replace with the URL to your trace data\n",
    "traces_url = \"https://storage.googleapis.com/arize-assets/phoenix/datasets/unstructured/llm/context-retrieval/trace.jsonl\"\n",
    "with urlopen(traces_url) as response:\n",
    "    lines = [line.decode(\"utf-8\") for line in response.readlines()]\n",
    "trace_ds = TraceDataset(json_lines_to_df(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNI [phoenix.session.session] Existing running Phoenix instance detected! Shutting it down and starting a new instance...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåç To view the Phoenix app in your browser, visit http://localhost:6006/\n",
      "üìñ For more information on how to use Phoenix, check out https://docs.arize.com/phoenix\n"
     ]
    }
   ],
   "source": [
    "import phoenix as px\n",
    "\n",
    "session = px.launch_app(trace=trace_ds)\n",
    "\n",
    "# session = px.launch_app(trace=px.TraceDataset(trace_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"query\", \"context\": {\"trace_id\": \"f40dc5d5-08b7-4e23-80e1-2cd6e9f0cf29\", \"span_id\": \"bce5b9ae-4587-4ead-9ccc-de3fe29257bc\"}, \"span_kind\": \"CHAIN\", \"parent_id\": null, \"start_time\": \"2023-12-11T17:57:17.891021+00:00\", \"end_time\": \"2023-12-11T17:57:20.075141+00:00\", \"status_code\": \"OK\", \"status_message\": \"\", \"attributes\": {\"input.value\": \"How can I query for a monitor\\'s status using GraphQL?\", \"input.mime_type\": \"text/plain\", \"output.value\": \"You can query for a monitor\\'s status using GraphQL by including the \\\\\"status\\\\\" field in your query.\", \"output.mime_type\": \"text/plain\"}, \"events\": [], \"conversation\": null}\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phoenix.evals import OpenAIModel, HallucinationEvaluator, QAEvaluator\n",
    "from phoenix.evals import run_evals\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # This is needed for concurrency in notebook environments\n",
    "\n",
    "# Set your OpenAI API key\n",
    "api_key = \"\"  # Replace with your actual API key\n",
    "eval_model = OpenAIModel(model=\"gpt-4-turbo-preview\", api_key=api_key)\n",
    "\n",
    "# Define your evaluators\n",
    "hallucination_evaluator = HallucinationEvaluator(eval_model)\n",
    "qa_evaluator = QAEvaluator(eval_model)\n",
    "\n",
    "# Assume 'queries_df' is your input dataframe \n",
    "# for `hallucination_evaluator` your input df needs to have columns 'output', 'input', 'context'\n",
    "# for `qa_evaluator` your input df needs to have columns 'output', 'input', 'reference'\n",
    "assert all(column in queries_df.columns for column in ['output', 'input', 'context', 'reference'])\n",
    "\n",
    "# Run the evaluators, each evaluator will return a dataframe with evaluation results\n",
    "# We upload the evaluation results to Phoenix in the next step\n",
    "hallucination_eval_df, qa_eval_df = run_evals(\n",
    "    dataframe=queries_df,\n",
    "    evaluators=[hallucination_evaluator, qa_evaluator],\n",
    "    provide_explanation=True\n",
    ")\n",
    "\n",
    "# Log the evaluations\n",
    "from phoenix.trace import SpanEvaluations\n",
    "\n",
    "px.Client().log_evaluations(\n",
    "    SpanEvaluations(eval_name=\"Hallucination\", dataframe=hallucination_eval_df),\n",
    "    SpanEvaluations(eval_name=\"QA Correctness\", dataframe=qa_eval_df)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
